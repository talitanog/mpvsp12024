{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talitanog/mpvsp12024/blob/main/prevsituacaoevento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificador de Contestação de Eventos de Mudança de Estado Operativo de Unidades Geradoras**\n",
        "\n",
        "**Contexto:** Temos um conjunto de dados que se chamam eventos. Eventos são as alterações de estados operativos de unidades geradoras de usinas térmicas, hidraulicas e nucleares. Cada mudança de disponibilidade da unidade geradora tem um evento registrado. Esse evento passa por uma primeira análise e depois é disponibilizado para o Agente Proprietário do equipamento. O Agente proprietário poderá discordar da primeira análise e esse evento então receberá um status diferente daquele inicial.\n",
        "Queremos identificar: dado um evento que possui informações de usina, unidade geradora, classificadores que indicam seu estado operativo, disponibilidade e data hora a previsão de contestação pelo agente. Ou seja, se o evento terá a classificação como \"NÃO ACORDADO\" após a primeira análise.\n",
        "\n",
        "\n",
        "**Estrtura:** Divisão do notebook:\n",
        "1. Importação das bibliotecas\n",
        "2. Configuração para não exibir warnings\n",
        "3. Acessando do dataset que será utilizado\n",
        "4. Tratamento dos dados\n",
        "5. Definição de features e target\n",
        "6. Divisão em Treino e Teste\n",
        "7. Treinamento do modelo machine learning\n",
        "8. Aplicação de Hiperparâmetros\n",
        "9. Finalização do Modelo\n",
        "10. Utilização do Modelo escolhido no treinamento\n",
        "11. Simulação em dados não vistos\n",
        "12. Conclusão\n",
        "\n"
      ],
      "metadata": {
        "id": "QuOmr6987EJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHECKLIST DEFINIÇÃO DO PROBLEMA**\n",
        "\n",
        "**Premissas e Hipóteses:**\n",
        "Não existe premissa, a principal hipótese é que determinados agentes, proprietários dos equipamentos apurados, através dos eventos do nosso dataset, irão sempre contestar um evento que possua determinadas características ou estiver em determinada sequência.\n",
        "Por isso, a tentativa de identificar uma regra através do modelo.\n",
        "\n",
        "**Restrições:**\n",
        "Um evento ele pode ser contestado em um primeiro momento e logo depois a equipe que faz a primeira análise pode concordar com essa contestação. Quando isso ocorre o evento fica com a classficação de \"Acordado\", como se ele nunca tivesse passado por uma contestação.\n",
        "Não vamos tratar essa mudança de status intermediária nesse trabalho.\n",
        "\n",
        "**Descreva o dataset:**\n",
        "usina_id: ID da Usina\n",
        "usina_nome: Nome da Usina\n",
        "unidade_geradora_id: ID da Unidade Geradora\n",
        "unidade_geradora_nome: Nome da Unidade Geradora\n",
        "evento_data_ocorrencia: Evento Data Ocorrência (data/hora em que houve mudança de disponibilidade da unidade geradora)\n",
        "evento_eo: Estado Operativo da Unidade Geradora (Ex: Ligada/Desligada)\n",
        "evento_co: Condição Operativo da Unidade Geradora (Ex: Normal/Restrição)\n",
        "evento_or: Origem da Condição Operativa da Unidade Geradora (Ex: Causa interna/externa/falta de combustível)\n",
        "evento_disponibilidade: Disponibilidade apresentada pela unidade geradora (Ex: 100MW)\n",
        "evento_status: Status do Evento\n",
        "evento_situacao: Acordado / Não Acordado"
      ],
      "metadata": {
        "id": "nKeSQY2ZRG5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importando as bibliotecas necessárias para executar o notebook**"
      ],
      "metadata": {
        "id": "Jq-rmQ-fQKKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiAuZ8xJC7tv"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as ms # para tratamento de missings\n",
        "from joblib import Parallel, delayed\n",
        "from matplotlib import cm\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Configuração para não exibir warnings**"
      ],
      "metadata": {
        "id": "oOFVGtZ1QtK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "dDgwp-y9DBvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Acessando dataset que será utilizado**"
      ],
      "metadata": {
        "id": "lN3F8MOQQ4zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "S6sifiMgqsg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lê o arquivo Excel\n",
        "eventos = pd.read_excel('/content/Cópia de eventos_talita_mba_v8.xlsx')\n",
        "\n",
        "# Exibe os primeiros registros do DataFrame\n",
        "print(eventos.head())"
      ],
      "metadata": {
        "id": "IP0M_PBhDE0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Tratamento dos dados**"
      ],
      "metadata": {
        "id": "Xea96iTnRakG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHECKLIST MODELAGEM E TREINAMENTO\n",
        "\n",
        "**Selecione os algoritmos mais indicados para o problema e dataset escolhidos, justificando as suas escolhas.**\n",
        "Abaixo justifico a retirada das colunas menos importantes. Na conclusão explico o porque mantive as colunas que foram utilizadas no treino.\n",
        "\n",
        "**Há algum ajuste inicial para os hiperparâmetros?**\n",
        "Sim, foi realizado após o primeiro treinamento.\n",
        "\n",
        "**O modelo foi devidamente treinado? Foi observado problema de underfitting?**\n",
        "Sim, Não identifiquei underfitting.\n",
        "\n",
        "**É possível otimizar os hiperparâmetros de algum dos modelos? Se sim, faça-o, justificando todas as escolhas.**\n",
        "Foi realizado, porém não apresentou grande variação. está detalhado no decorrer do notebook.\n",
        "\n",
        "**Há algum método avançado ou mais complexo que possa ser avaliado?**\n",
        "Sim, acredito que novas variáveis podem ser adicionadas, inclusive status intermediários dos eventos.\n",
        "\n",
        "**Posso criar um comitê de modelos diferentes para o problema (ensembles)?**\n",
        "Sim, foi realizado no meu trabaho de classificação, explicado também na conclusão. Porém, não utilizado. Realizei o Bagging, Random Forest, Boosting, etc.\n"
      ],
      "metadata": {
        "id": "TilGxY4VUKjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'evento_data_ocorrencia' para o tipo datetime\n",
        "eventos['evento_data_ocorrencia'] = pd.to_datetime(eventos['evento_data_ocorrencia'])"
      ],
      "metadata": {
        "id": "QoObFxM7M-Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa coluna evento_data_ocorrência em 05 colunas para cada tipo de informação\n",
        "eventos['ano'] = eventos['evento_data_ocorrencia'].dt.year\n",
        "eventos['mes'] = eventos['evento_data_ocorrencia'].dt.month\n",
        "eventos['dia'] = eventos['evento_data_ocorrencia'].dt.day\n",
        "eventos['hora'] = eventos['evento_data_ocorrencia'].dt.hour\n",
        "eventos['minuto'] = eventos['evento_data_ocorrencia'].dt.minute"
      ],
      "metadata": {
        "id": "Vr6IK_PjNEXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclusão de colunas desnecessárias para a análise\n",
        "eventos = eventos.drop(['usina_nome','evento_data_ocorrencia', 'unidade_geradora_nome', 'evento_status'], axis=1)\n",
        "print (eventos.head())"
      ],
      "metadata": {
        "id": "4sqrG8PWg_g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Razão para exclusão dos campos:\n",
        "\n",
        "1. usina_nome: Mantive a coluna de ids da usina\n",
        "2. evento_data_ocorrencia: Essa coluna foi traduzida em 05 colunas conforme comando acima.\n",
        "3. unidade_geradora_nome: Mantive a coluna de ids das unidades geradoras\n",
        "4. evento_status: Essa coluna foi traduzida na coluna target\n"
      ],
      "metadata": {
        "id": "mssAJuy89MQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenação das colunas\n",
        "nova_ordem_colunas = ['usina_id','unidade_geradora_id', 'evento_eo', 'evento_co', 'evento_or', 'evento_disponibilidade', 'ano','mes','dia','hora','minuto','evento_situacao']\n",
        "\n",
        "# Reordenar as colunas do DataFrame\n",
        "eventos = eventos[nova_ordem_colunas]\n",
        "\n",
        "print (eventos.head())"
      ],
      "metadata": {
        "id": "PC_ZZlCjNzFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para converter as variáveis categóricas evento_eo, evento_co e evento_or utilizei o one hot encoding.\n",
        "Significado de cada um desses atributos:\n",
        "evento_eo: Estado Operativo, em resumo essa informação define se o evento representa que a unidade geradora está ligada ou desligada.\n",
        "evento_co: Condição Operativa, resumidamente define em que condições a unidade geradora está ligada, as condições podem ser Normal ou Restrição.\n",
        "evento_or: Origem, resumidamente diz qual a origem do desligamento ou da restrição que a unidade geradora está apresentando."
      ],
      "metadata": {
        "id": "rJUNhx4s-CRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar One-Hot Encoding para as colunas 'evento_eo', 'evento_co' e 'evento_or'\n",
        "eventos_encoded = pd.get_dummies(eventos, columns=['evento_eo', 'evento_co', 'evento_or'])\n",
        "\n",
        "# Exibir o DataFrame com as colunas codificadas\n",
        "print(eventos_encoded)"
      ],
      "metadata": {
        "id": "QV3EUSq_ejfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a transformação da coluna target em variáveis numéricas utilizei o Label encoder.\n",
        "A coluna evento_situacao foi transformada em evento_situacao_num.\n"
      ],
      "metadata": {
        "id": "oGounRPp_Rrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie uma instância do LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajuste o LabelEncoder aos valores da coluna target\n",
        "label_encoder.fit(eventos_encoded['evento_situacao'])\n",
        "\n",
        "# Transforme os valores da coluna target em valores numéricos\n",
        "evento_situacao_num = label_encoder.transform(eventos_encoded['evento_situacao'])\n",
        "\n",
        "# Adicione a coluna transformada de volta ao DataFrame\n",
        "eventos_encoded['evento_situacao_num'] = evento_situacao_num\n",
        "\n",
        "# Agora a coluna 'evento_situacao_num' estará presente no DataFrame eventos_encoded\n",
        "evento_situacao_num"
      ],
      "metadata": {
        "id": "E-pCQZ7DqX_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apenas dois valores foram determinados para essa atividade. \"Acordado\" através do LabelEncoder virou 0 e 1 \"Não Acordado\"\n",
        "\n",
        "Abaixo confirmei todas as colunas do dataset"
      ],
      "metadata": {
        "id": "5I_SvG7M1jTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for coluna in eventos_encoded.columns:\n",
        "  print(coluna)"
      ],
      "metadata": {
        "id": "jSUixK8JwOvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar os valores de evento_situacao e evento_situacao_num\n",
        "print(eventos_encoded['evento_situacao'])\n",
        "print(eventos_encoded['evento_situacao_num'])"
      ],
      "metadata": {
        "id": "k_WVl_-ad9_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Definição de target**"
      ],
      "metadata": {
        "id": "mXkKSLufAwau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação de colunas e definição target\n",
        "\n",
        "# Remover a coluna original após a codificação\n",
        "eventos_encoded = eventos_encoded.drop(columns=['evento_situacao'])\n",
        "\n",
        "# Definição do Target\n",
        "coluna_target = 'evento_situacao_num'\n",
        "\n",
        "# Definição das Features\n",
        "features = eventos_encoded.drop(columns=[coluna_target])\n"
      ],
      "metadata": {
        "id": "DqNppj82ZPNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Divisão de Treino e teste**"
      ],
      "metadata": {
        "id": "xZuK9bu612y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos Dados em treino e teste\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, eventos_encoded[coluna_target], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gVR4s86YjnHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "ktG8aEryn368"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "5B665IMAobmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "XTaqTEhpooe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "F_i6_KshowFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Treinamento do modelo machine learning**"
      ],
      "metadata": {
        "id": "WhyDl0ryBAvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo uma seed global para o gerador de números aleatórios\n",
        "np.random.seed(42)\n",
        "\n",
        "# Definir o número de folds para a validação cruzada\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "# Listas para armazenar os modelos, os resultados e os nomes dos modelos\n",
        "models = []\n",
        "results = {'LR': [], 'Ridge': [], 'Lasso': [], 'CART': []}\n",
        "names = []\n",
        "\n",
        "# Preparando os modelos e adicionando-os em uma lista\n",
        "models.append(('LR', LinearRegression()))\n",
        "models.append(('Ridge', Ridge()))\n",
        "models.append(('Lasso', Lasso()))\n",
        "models.append(('CART', DecisionTreeRegressor()))\n",
        "\n",
        "# Avaliando um modelo por vez\n",
        "for name, model in models:\n",
        "    scoring = {'neg_mean_squared_error': 'neg_mean_squared_error', 'r2': make_scorer(r2_score), 'mae': make_scorer(mean_absolute_error)}\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results[name] = cv_results\n",
        "    names.append(name)\n",
        "    # Imprime as métricas dos 10 resultados da validação cruzada\n",
        "    msg = \"%s: MSE %0.2f (%0.2f) - RMSE %0.2f, R² %0.2f, MAE %0.2f\" % (\n",
        "        name, abs(cv_results['test_neg_mean_squared_error'].mean()),\n",
        "        cv_results['test_neg_mean_squared_error'].std(),\n",
        "        np.sqrt(abs(cv_results['test_neg_mean_squared_error'].mean())),\n",
        "        cv_results['test_r2'].mean(),\n",
        "        cv_results['test_mae'].mean())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparação do MSE, R² e MAE dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot([results[name]['test_neg_mean_squared_error'] for name in names])\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3dv8n_w_PiAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os modelos LR e Ridge apresentaram resultados semelhantes, porém a Árvore de Decisão apresentou o melhor resultado"
      ],
      "metadata": {
        "id": "xhIN46P_HyYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1. Comparação entre modelos"
      ],
      "metadata": {
        "id": "31imXtdB2W3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot de comparação dos modelos\n",
        "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
        "fig.suptitle('Comparação do MSE, R² e MAE dos Modelos')\n",
        "\n",
        "# Boxplot para MSE\n",
        "ax1 = axes[0]\n",
        "ax1.boxplot([results[name]['test_neg_mean_squared_error'] for name in names])\n",
        "ax1.set_xticklabels(names)\n",
        "ax1.set_title('Comparação do MSE dos Modelos')\n",
        "\n",
        "# Gráfico de barras para R²\n",
        "ax2 = axes[1]\n",
        "ax2.bar(names, [results[name]['test_r2'].mean() for name in names])\n",
        "ax2.set_title('Comparação do R² dos Modelos')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "arOikrKnQcFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A árvore de decisão tem um desempenho muito melhor, observando o MSE e RMSE que são muito baixos, indicando uma boa precisão, o R² próximo a 1 sugere que o modelo explica quase toda a variabilidade nos dados e o MAE é praticamente zero, o que indica um ajuste muito preciso aos dados."
      ],
      "metadata": {
        "id": "K2JCSbxgH8Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Hiperparâmetros**"
      ],
      "metadata": {
        "id": "LftkhH8Pp6K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=DecisionTreeRegressor(),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           cv=10,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "-hAznzYtrZ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1. Apresentação dos resultados"
      ],
      "metadata": {
        "id": "_IL3MnCl3Wxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(\"Melhores parâmetros:\", best_params)\n"
      ],
      "metadata": {
        "id": "otgEqtrGyN8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "print(\"Melhor modelo:\", best_model)"
      ],
      "metadata": {
        "id": "6HjMZuyJywzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = grid_search.cv_results_\n",
        "print(\"Resultados da validação cruzada:\", cv_results)"
      ],
      "metadata": {
        "id": "TCBXZ2dxy4zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. Resultados após a aplicação de Hiperparâmetros"
      ],
      "metadata": {
        "id": "XNdJw69V3yAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão do modelo\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Coeficiente de Determinação (R²)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Coeficiente de Determinação (R²):\", r2)\n",
        "\n",
        "# Erro Absoluto Médio (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Erro Absoluto Médio (MAE):\", mae)\n",
        "\n",
        "# Raiz do Erro Quadrático Médio (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Raiz do Erro Quadrático Médio (RMSE):\", rmse)"
      ],
      "metadata": {
        "id": "IANqPsIxzR1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não tivemos grandes melhorias em aplicar o hiperparâmetro."
      ],
      "metadata": {
        "id": "ZR8g_7QI38Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Finalização do modelo**"
      ],
      "metadata": {
        "id": "IvS82MZFB-gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42) # Definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "# Modelos que serão utilizados\n",
        "linear_reg = ('LR', LinearRegression())\n",
        "ridge = ('Ridge', Ridge())\n",
        "lasso = ('Lasso', Lasso())\n",
        "decision_tree = ('CART', DecisionTreeClassifier())\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('LR-orig', Pipeline([linear_reg])))\n",
        "pipelines.append(('Ridge-orig', Pipeline([ridge])))\n",
        "pipelines.append(('Lasso-orig', Pipeline([lasso])))\n",
        "pipelines.append(('CART-orig', Pipeline([decision_tree])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('LR-padr', Pipeline([standard_scaler, linear_reg])))\n",
        "pipelines.append(('Ridge-padr', Pipeline([standard_scaler, ridge])))\n",
        "pipelines.append(('Lasso-padr', Pipeline([standard_scaler, lasso])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, decision_tree])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('LR-norm', Pipeline([min_max_scaler, linear_reg])))\n",
        "pipelines.append(('Ridge-norm', Pipeline([min_max_scaler, ridge])))\n",
        "pipelines.append(('Lasso-norm', Pipeline([min_max_scaler, lasso])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, decision_tree])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results['test_neg_mean_squared_error'].mean(), cv_results['test_neg_mean_squared_error'].std()) # Formatando para 3 casas decimais\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot([result['test_neg_mean_squared_error'] for result in results])\n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dWl9MnCaCECj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajuste do negativo do MSE.\n",
        "Todos os modelos de regressão do Ridge e LR tiveram desempenho semelhante.\n",
        "Os modelos do Lasso tiveram um desempenho pior comparados com os outros modelos.\n",
        "O modelo que teve melhor desempenho foi o DecisionTree\n",
        ".\n"
      ],
      "metadata": {
        "id": "hWx4niOs4Ytw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1. Matriz de Confusão"
      ],
      "metadata": {
        "id": "O8Kjy9_J4hBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "eg9pY6spCIZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo parece estar tendo um bom desempenho pelo resultado da matrix. Os valores de verdadeiro positivo e verdadeiro negativo são altos."
      ],
      "metadata": {
        "id": "BcKaMw9L4oX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2. Preparação do modelo escolhido usando a pipeline"
      ],
      "metadata": {
        "id": "7LBMEb5E40a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo uma semente global para este bloco\n",
        "np.random.seed(42)\n",
        "\n",
        "# Preparação do modelo usando Pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Padronização dos dados\n",
        "    ('model', DecisionTreeClassifier())  # Modelo de regressão linear\n",
        "])\n",
        "\n",
        "# Treinamento do modelo com o conjunto de treinamento\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "predictions = model_pipeline.predict(X_test)\n",
        "\n",
        "# Calculando as métricas de avaliação\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Coeficiente de Determinação (R²):\", r2)\n",
        "print(\"Erro Absoluto Médio (MAE):\", mae)"
      ],
      "metadata": {
        "id": "7NwmylGBCL1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de regressão está performando bem. O MSE, R² e MAE apresentam valores baixos."
      ],
      "metadata": {
        "id": "RyLWakTGLaDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "scaler = StandardScaler().fit(eventos_encoded) # ajuste do scaler com TODO o dataset\n",
        "rescaledX = scaler.transform(eventos_encoded) # aplicação da padronização com TODO o dataset\n",
        "model.fit(rescaledX, eventos_encoded['evento_situacao_num'])"
      ],
      "metadata": {
        "id": "kqlSTl-tCREh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Utilizando modelo Decision Tree em dados novos**"
      ],
      "metadata": {
        "id": "skH4CDPfL_em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1. Importando arquivo"
      ],
      "metadata": {
        "id": "dxhgHKr8600e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lê o arquivo Excel de trabalho [Dados não conhecidos]\n",
        "eventos_novos = pd.read_excel('/content/trabalhov2.xlsx')\n",
        "\n",
        "# Exibe os primeiros registros do DataFrame\n",
        "print(eventos_novos.head())"
      ],
      "metadata": {
        "id": "ymZrnLKpWFNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2. Tratamento dos dados para ser lido pelo modelo"
      ],
      "metadata": {
        "id": "3xXT0TP_M3RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'evento_data_ocorrencia' para o tipo datetime\n",
        "eventos_novos['evento_data_ocorrencia'] = pd.to_datetime(eventos_novos['evento_data_ocorrencia'])"
      ],
      "metadata": {
        "id": "aoIBiaCQHsxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa coluna evento_data_ocorrência em 05 colunas para cada tipo de informação\n",
        "eventos_novos['ano'] = eventos_novos['evento_data_ocorrencia'].dt.year\n",
        "eventos_novos['mes'] = eventos_novos['evento_data_ocorrencia'].dt.month\n",
        "eventos_novos['dia'] = eventos_novos['evento_data_ocorrencia'].dt.day\n",
        "eventos_novos['hora'] = eventos_novos['evento_data_ocorrencia'].dt.hour\n",
        "eventos_novos['minuto'] = eventos_novos['evento_data_ocorrencia'].dt.minute"
      ],
      "metadata": {
        "id": "rT0USyANKpxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclusão de colunas desnecessárias para a análise\n",
        "eventos_novos = eventos_novos.drop(['usina_nome','evento_data_ocorrencia', 'unidade_geradora_nome'], axis=1)\n",
        "print (eventos_novos.head())"
      ],
      "metadata": {
        "id": "KuOF14U5K_R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenação das colunas\n",
        "ordenacao_colunas = ['usina_id','unidade_geradora_id', 'evento_eo', 'evento_co', 'evento_or', 'evento_disponibilidade', 'ano','mes','dia','hora','minuto']\n",
        "\n",
        "# Reordenar as colunas do DataFrame\n",
        "eventos_novos = eventos_novos[ordenacao_colunas]\n",
        "\n",
        "print (eventos_novos.head())"
      ],
      "metadata": {
        "id": "mbJ0-9r3LelT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar One-Hot Encoding para as colunas 'evento_eo', 'evento_co' e 'evento_or'\n",
        "eventos_novos_encoded = pd.get_dummies(eventos_novos, columns=['evento_eo', 'evento_co', 'evento_or'])\n",
        "\n",
        "# Exibir o DataFrame com as colunas codificadas\n",
        "print(eventos_novos_encoded)"
      ],
      "metadata": {
        "id": "PTZo_fZjflS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3. Confirmação se as features são as mesmas"
      ],
      "metadata": {
        "id": "ay_zbRsl7O1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se os nomes das colunas nos dados de treinamento e nos dados de eventos novos são os mesmos\n",
        "columns_X_train = set(X_train.columns)\n",
        "columns_eventos_novos_encoded = set(eventos_novos_encoded.columns)\n",
        "\n",
        "# Verificar se todas as colunas de X_train estão presentes em eventos_novos_encoded\n",
        "missing_columns_in_eventos_novos_encoded = columns_X_train - columns_eventos_novos_encoded\n",
        "\n",
        "# Verificar se todas as colunas de eventos_novos_encoded estão presentes em X_train\n",
        "missing_columns_in_X_train = columns_eventos_novos_encoded - columns_X_train\n",
        "\n",
        "missing_columns_in_eventos_novos_encoded, missing_columns_in_X_train"
      ],
      "metadata": {
        "id": "xUmxsSMuXpFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista das colunas presentes em X_train, mas ausentes em eventos_novos_encoded\n",
        "colunas_ausentes = list(missing_columns_in_eventos_novos_encoded)\n",
        "\n",
        "# Adicionar as colunas ausentes aos dados de eventos_novos_encoded e preenchê-las com \"falso\"\n",
        "for col in colunas_ausentes:\n",
        "    eventos_novos_encoded[col] = False\n",
        "\n",
        "# Verificar se todas as colunas de X_train agora estão presentes em eventos_novos_encoded\n",
        "missing_columns_in_eventos_novos_encoded = set(X_train.columns) - set(eventos_novos_encoded.columns)\n",
        "\n",
        "# Exibir as colunas ausentes após a adição\n",
        "print(\"Colunas ausentes em eventos_novos_encoded após a adição:\", missing_columns_in_eventos_novos_encoded)"
      ],
      "metadata": {
        "id": "jUymZ-RFmYAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar os recursos nos dados de entrada e treinamento\n",
        "features_input = eventos_novos_encoded.columns.tolist()\n",
        "features_training = X_train.columns.tolist()\n",
        "\n",
        "# Comparar os conjuntos de recursos\n",
        "if set(features_input) == set(features_training):\n",
        "    print(\"Os conjuntos de recursos são iguais.\")\n",
        "else:\n",
        "    print(\"Os conjuntos de recursos são diferentes.\")\n",
        "\n",
        "    # Identificar as diferenças\n",
        "    features_only_in_input = set(features_input) - set(features_training)\n",
        "    features_only_in_training = set(features_training) - set(features_input)\n",
        "\n",
        "    # Exibir os detalhes dos recursos\n",
        "    print(\"Recursos presentes nos dados de entrada:\")\n",
        "    print(features_input)\n",
        "    print(\"\\nRecursos presentes nos dados de treinamento:\")\n",
        "    print(features_training)\n",
        "\n",
        "    # Exibir qualquer diferença\n",
        "    if features_only_in_input:\n",
        "        print(\"\\nRecursos presentes apenas nos dados de entrada:\")\n",
        "        print(features_only_in_input)\n",
        "    if features_only_in_training:\n",
        "        print(\"\\nRecursos presentes apenas nos dados de treinamento:\")\n",
        "        print(features_only_in_training)\n",
        "\n"
      ],
      "metadata": {
        "id": "1BS_1PFwb4MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as características presentes nos dados de entrada e nos dados usados para treinar o escalador\n",
        "features_scaler = scaler.get_feature_names_out()\n",
        "features_input_data = eventos_novos_encoded.columns\n",
        "\n",
        "if set(features_scaler) != set(features_input_data):\n",
        "    # Se os conjuntos de características forem diferentes, ajuste o escalador novamente\n",
        "    scaler.fit(eventos_novos_encoded)\n",
        "\n",
        "# Escalonar os novos dados\n",
        "eventos_novos_scaled = scaler.transform(eventos_novos_encoded)\n"
      ],
      "metadata": {
        "id": "Tlk7Fp2GhIm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Simulando a aplicação do modelo em dados não vistos**"
      ],
      "metadata": {
        "id": "OfCokAhs4zFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista das colunas presentes em X_train, mas ausentes em eventos_novos_encoded\n",
        "colunas_ausentes = list(set(X_train.columns) - set(eventos_novos_encoded.columns))\n",
        "\n",
        "# Adicionar as colunas ausentes aos dados de eventos_novos_encoded e preenchê-las com \"falso\"\n",
        "for col in colunas_ausentes:\n",
        "    eventos_novos_encoded[col] = False\n",
        "\n",
        "# Escalonar os novos dados\n",
        "eventos_novos_scaled = scaler.transform(eventos_novos_encoded)\n",
        "\n",
        "# Fazer previsões nos novos dados usando o modelo treinado\n",
        "predictions = model_pipeline.predict(eventos_novos_scaled)  # Aqui está a correção\n",
        "\n",
        "# Exibir as previsões\n",
        "print(predictions)\n",
        "\n",
        "# Criar um DataFrame com as features de entrada (opcional)\n",
        "dados_entrada = pd.DataFrame(eventos_novos_encoded, columns=X_train.columns)\n",
        "\n",
        "# Adicionar uma coluna com os dados preditos\n",
        "dados_entrada['evento_situacao_num_predito'] = predictions\n",
        "\n",
        "# Exibir o DataFrame com os dados de entrada e os dados preditos (opcional)\n",
        "print(dados_entrada)"
      ],
      "metadata": {
        "id": "DqO8NBx1asbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.1. Fazendo predições em dados novos"
      ],
      "metadata": {
        "id": "E8ZSsa1p8vFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões nos novos dados usando o modelo treinado\n",
        "predictions = model_pipeline.predict(eventos_novos_scaled)\n",
        "\n",
        "# Criar um DataFrame com as features de entrada e as previsões\n",
        "dados_entrada_predicao = pd.DataFrame(eventos_novos_encoded, columns=X_train.columns)\n",
        "dados_entrada_predicao['evento_situacao_num_predito'] = predictions\n",
        "\n",
        "# Mapear as previsões de volta para as classes originais (se necessário)\n",
        "# predictions_mapped = map_classes(predictions)  # Implemente essa função se aplicável\n",
        "\n",
        "# Adicionar as previsões mapeadas ao DataFrame\n",
        "# dados_entrada_predicao['evento_situacao_predito'] = predictions_mapped\n",
        "\n",
        "# Exibir o DataFrame com os dados de entrada e as previsões\n",
        "print(dados_entrada_predicao)"
      ],
      "metadata": {
        "id": "W0p32QXKkj_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2. Análise de Resultados"
      ],
      "metadata": {
        "id": "oML8bK8r9CRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de ocorrências de cada classe prevista\n",
        "previsoes_counts = dados_entrada_predicao['evento_situacao_num_predito'].value_counts()\n",
        "\n",
        "# Plotar o gráfico de barras\n",
        "plt.figure(figsize=(8, 6))\n",
        "previsoes_counts.plot(kind='bar')\n",
        "plt.title('Distribuição das Previsões')\n",
        "plt.xlabel('Classe Prevista')\n",
        "plt.ylabel('Número de Ocorrências')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RXGwW5Ksk2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de ocorrências de cada classe prevista\n",
        "previsoes_counts = dados_entrada['evento_situacao_num_predito'].value_counts()\n",
        "\n",
        "# Plotar o gráfico de barras\n",
        "plt.figure(figsize=(8, 6))\n",
        "previsoes_counts.plot(kind='bar')\n",
        "plt.title('Distribuição das Previsões')\n",
        "plt.xlabel('Classe Prevista')\n",
        "plt.ylabel('Número de Ocorrências')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HPF7EAORtO6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de ocorrências de cada classe prevista\n",
        "previsoes_counts = dados_entrada['evento_situacao_num_predito'].value_counts()\n",
        "\n",
        "# Plotar o gráfico de barras\n",
        "plt.figure(figsize=(8, 6))\n",
        "previsoes_counts.plot(kind='bar')\n",
        "plt.title('Distribuição das Previsões')\n",
        "plt.xlabel('Classe Prevista')\n",
        "plt.ylabel('Número de Ocorrências')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FzmE9Tq1tNiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de ocorrências de cada classe prevista\n",
        "previsoes_counts = dados_entrada['evento_situacao_num_predito'].value_counts()\n",
        "\n",
        "# Imprimir os valores totais\n",
        "print(\"Total de predições classe 0:\", previsoes_counts[0])\n",
        "print(\"Total de predições classe 1:\", previsoes_counts[1])"
      ],
      "metadata": {
        "id": "0ateLuy-tgKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# CHECKLIST AVALIAÇÃO DE RESULTADOS**\n",
        "\n",
        "**Selecione as métricas de avaliação condizentes com o problema, justificando.**\n",
        "As métricas selecionadas estão descritas no notebook\n",
        "Mean Squared Error (MSE - Erro Quadrático Médio):\n",
        "O MSE é uma medida do erro médio quadrático entre os valores previstos pelo modelo e os valores reais. Quanto menor o valor do MSE, melhor o desempenho do modelo em fazer previsões precisas.\n",
        "\n",
        "Coeficiente de Determinação (R²):\n",
        "O R² é uma medida estatística que indica a proporção da variância dos valores dependentes que é explicada pelos valores previstos pelo modelo. Um R² mais próximo de 1 indica um ajuste muito bom do modelo aos dados.\n",
        "\n",
        "Erro Absoluto Médio (MAE):\n",
        "O MAE é a média das diferenças absolutas entre os valores previstos pelo modelo e os valores reais. Assim como o MSE, quanto menor o valor do MAE, melhor o desempenho do modelo em fazer previsões precisas.\n",
        "\n",
        "**Treine o modelo escolhido com toda a base de treino, e teste-o com a base de teste.**\n",
        "Realizado, está no decorrer do notebook\n",
        "\n",
        "**Os resultados fazem sentido?**\n",
        "Sim, confirmou que o modelo está atuando de forma aceitável.\n",
        "\n",
        "**Foi observado algum problema de overfitting?**\n",
        "Não\n",
        "\n",
        "**Compare os resultados de diferentes modelos.**\n",
        "Modelos comparados no decorrer do notebook\n",
        "\n",
        "**Descreva a melhor solução encontrada, justificando.**\n",
        "Árvore de Decisão, justificativa na conclusão."
      ],
      "metadata": {
        "id": "b81oWLHWWas9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. Conclusão**"
      ],
      "metadata": {
        "id": "Zul7zBrq9MIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante a análise do trabalho, fiquei na dúvida em treinar um modelo de  regressão linear ou de classificação.\n",
        "A justificativa para regressão linear é que a data hora do evento é algo importante para a análise da situação do evento (Acordado e Não Acordado). E essa informação varia demais, então o ideal é analisar as datas horas futuras juntamente com a sequência de eventos que a unidade geradora possui. Por isso, tinha uma tese que o melhor seria regressão linear.\n",
        "Por outro lado, o resultado é praticamente dois: Acordado e Não Acordado e isso é mais utilizado para problemas de classificação.\n",
        "Diante disso, fiz um novo notebook com modelos de classificação. E nesse outro notebook o modelo que teve melhor acurácia também foi a Árvore de Decisão. Com medidas tão altas quanto as de regressão linear.\n",
        "Por isso resolvi manter esse trabalho utilizando a Regressão Linear. Acredito que não faça diferença já que ela pode ser utilizada tanto para classificação quanto para Regressão.\n",
        "Mais razões apra utilizar a Árvore de Decisão:\n",
        "\n",
        "\n",
        "\n",
        "*   Melhor desempenho comparado com outros modelos\n",
        "*   A aplicação de hiperparâmetros não resultou em melhorias significativas no desempenho do modelo, indicando que o modelo original já estava bem ajustado aos dados.\n",
        "\n",
        "*   A matriz de confusão mostrou que o modelo teve um desempenho\n",
        "*   O modelo treinado foi aplicado com sucesso a novos dados, mostrando sua capacidade de generalização.\n",
        "\n",
        "\n",
        "*   A distribuição das previsões mostra que o modelo classificou os eventos de mudança de estado operativo com precisão, com um número significativo de previsões para cada classe\n",
        "*   Item da lista\n",
        "\n",
        "\n",
        "**Justificativa para não utilizar Feature Selection**\n",
        "Todas as informações relevantes para a análise de consistência do evento foram mantidas no dadaset. Retirei informações que não interessavam para a análise e por isso não achei necessário realizar um tratamento via código da feature selection.\n",
        "Informações que entendo que são importantes e foram mantidas:\n",
        "\n",
        "**Usina e Unidade Geradora:** São os agentes proprietários desses equipamentos que determinam a situação do evento. Por isso, foram mantidos, podendo ser determinante para a análise. Por exemplo, o agente X pode sempre contestar um determinado evento.\n",
        "\n",
        "**Classificadores como evento estado operativo (evento_eo), evento condição operativa (evento_co) e evento origem (evento_or):** Determinam a condição que uma unidade geradora estava. Isso altera a sua disponibilidade e é motivo de análise principal dos agentes.\n",
        "\n",
        "**Disponibilidade  e data hora:** mesmo caso acima, são pontos importantes para análise dos agentes.\n",
        "\n",
        "**Conclusão Geral:**\n",
        "O modelo desenvolvido demonstrou ser eficaz na previsão de contestação de eventos de mudança de estado operativo de unidades geradoras.\n",
        "No entanto, algumas melhorias precisam ser realizadas, pois proporcionalmente o número de erros se apresenta pequento diante do dataset. É necessário realizar testes com períodos diferentes e colunas novas, não utilizadas no treinamento para que o modelo fique mais eficaz na classificação."
      ],
      "metadata": {
        "id": "ris8R9IK9SCo"
      }
    }
  ]
}